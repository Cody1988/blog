Start Hadoop

$HADOOP_HOME/bin/hdfs namenode -format

$HADOOP_HOME/sbin/start-dfs.sh

$HADOOP_HOME/sbin/start-yarn.sh

$HADOOP_HOME/sbin/mr-jobhistory-daemon.sh --config $HADOOP_CONF_DIR start historyserver

http://localhost:50070/
http://localhost:8088/cluster

Hadoop temp directory: /usr/local/hadoop/hadoop-2.8.0/hdfs-tmp


Creating a directory

hdfs dfs -mkdir /paawak


hdfs dfs -put src/main/resources/Country.csv

hadoop fs -rm -r /paawak/out*


hadoop jar target/hadoop-demo-1.0-SNAPSHOT.jar com.swayam.demo.hadoop.MovieRatings /paawak/ratings.dat /paawak/out-ratings


Init Hive
schematool -dbType mysql -initSchema


Starting Hive
hive --service metastore 



For importing data with Sqoop:
sqoop import --connect jdbc:mysql://localhost:3306/datasets --username root -P --table bank_details -m 1 --target-dir /user/paawak/sqoop/bank_details

sqoop import --connect jdbc:mysql://localhost:3306/datasets --username root -P --table bank_details -m 1 --hive-import --hive-table bank_details_staging


Using Pig with Hcatalog:
pig -useHCatalog



spark-submit --class com.swayam.demo.bigdata.spark.HelloSparkApp \
--master local --deploy-mode client --executor-memory 1g \
--name HelloSparkApp --conf "spark.app.id=HelloSparkApp" \
target/spark-demo-1.0-SNAPSHOT.jar 



